{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffffb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import joblib \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import joblib\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "import lightgbm as lgb\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692352dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales_train_evaluation.csv')\n",
    "sales.name = 'sales'\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "calendar.name = 'calendar'\n",
    "prices = pd.read_csv('sell_prices.csv')\n",
    "prices.name = 'prices'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab667e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30490, 1947)\n",
      "(1969, 14)\n",
      "(6841121, 4)\n"
     ]
    }
   ],
   "source": [
    "print(sales.shape)\n",
    "print(calendar.shape)\n",
    "print(prices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b38d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2acbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['cat_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['dept_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d776bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['store_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd100385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['store_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e320e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add zero sales for the remaining days 1942-1969\n",
    "for d in range(1948,1970):\n",
    "    col = 'd_' + str(d)\n",
    "    sales[col] = 0\n",
    "    sales[col] = sales[col].astype(np.int16)\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b963246",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cecd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73da0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['event_type_1'].fillna('No event1',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['event_type_2'].fillna('No event2',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798727f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed11a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ffb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "    for i,t in enumerate(types):\n",
    "        if 'int' in str(t):\n",
    "            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
    "        elif 'float' in str(t):\n",
    "            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float16)\n",
    "            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
    "        elif t == np.object:\n",
    "            if cols[i] == 'date':\n",
    "                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype('category')\n",
    "    return df  \n",
    "\n",
    "sales = downcast(sales)\n",
    "prices = downcast(prices)\n",
    "calendar = downcast(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35943147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n",
    "             var_name='d', value_name='sold').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9685c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1917eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, calendar, on='d', how='left')\n",
    "df = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84be10bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59181090, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236d8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b93d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f6525",
   "metadata": {},
   "source": [
    "As we have seen stats based model does not perform well on our data, we will do featture engineering and apply machine learning based Algoritham "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39ad72",
   "metadata": {},
   "source": [
    "Feature engineering based on Above EDA ."
   ]
  },
  {
   "cell_type": "raw",
   "id": "85f3e9b5",
   "metadata": {},
   "source": [
    "Encoding Categorical features: \n",
    "department, \n",
    "category,\n",
    "store, \n",
    "state,\n",
    "wday, \n",
    "event_type_1-2, \n",
    "Snap days(Already encoded)\n",
    "\n",
    "\n",
    "Calculate mean based feature :\n",
    "    \n",
    "    \n",
    "state\n",
    "store\n",
    "category\n",
    "department\n",
    "category Average \n",
    "department & item\n",
    "category & department\n",
    "state & store\n",
    "state, store and category\n",
    "store, category and department\n",
    "\n",
    "Add lag , rolling window, expanding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027716a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3884806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoding(train, feature):    \n",
    "    encoder = LabelEncoder()\n",
    "    train[feature] = encoder.fit_transform(df[feature])\n",
    "    \n",
    "    return train[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d90ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id']  = label_encoding(df,\"id\" )\n",
    "df['dept_id']  = label_encoding(df,\"dept_id\" )\n",
    "df['cat_id'] = label_encoding(df,\"cat_id\" )\n",
    "df['store_id']  = label_encoding(df,\"store_id\" )\n",
    "df['state_id']  = label_encoding(df,\"state_id\" )\n",
    "df['event_type_1']  = label_encoding(df,\"event_type_1\" )\n",
    "df['event_type_2']  = label_encoding(df,\"event_type_2\" )\n",
    "df['event_name_1']  = label_encoding(df,\"event_type_1\" )\n",
    "df['event_name_2']  = label_encoding(df,\"event_type_2\" )\n",
    "df['weekday']  = label_encoding(df,\"weekday\" )\n",
    "df['item_id']  = label_encoding(df,\"item_id\" )\n",
    "df['wm_yr_wk']  = label_encoding(df,\"wm_yr_wk\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a729123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29457d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6412a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            int32         \n",
      " 1   item_id       int32         \n",
      " 2   dept_id       int32         \n",
      " 3   cat_id        int32         \n",
      " 4   store_id      int32         \n",
      " 5   state_id      int32         \n",
      " 6   d             int16         \n",
      " 7   sold          int16         \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int64         \n",
      " 10  weekday       int32         \n",
      " 11  wday          int8          \n",
      " 12  month         int8          \n",
      " 13  year          int16         \n",
      " 14  event_name_1  int64         \n",
      " 15  event_type_1  int64         \n",
      " 16  event_name_2  int64         \n",
      " 17  event_type_2  int64         \n",
      " 18  snap_CA       int8          \n",
      " 19  snap_TX       int8          \n",
      " 20  snap_WI       int8          \n",
      " 21  sell_price    float16       \n",
      "dtypes: datetime64[ns](1), float16(1), int16(3), int32(7), int64(5), int8(5)\n",
      "memory usage: 5.3 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "174630bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifting = 28 #shift period in order to account for 28 days to forecast\n",
    "df['lag_'+str(shifting)] = df.groupby('id')['sold'].shift(shifting).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f169a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce lags\n",
    "lags = [7,14]\n",
    "for lag in lags:\n",
    "    df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['lag_28'].shift(lag).astype(np.float16).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1018aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['state_sold_avg'] = df.groupby('state_id')['lag_28'].transform('mean').astype(np.float16)\n",
    "df['dept_sold_avg'] = df.groupby('dept_id')['lag_28'].transform('mean').astype(np.float16)\n",
    "df['cat_sold_avg'] = df.groupby('cat_id')['lag_28'].transform('mean').astype(np.float16)\n",
    "df['cat_daily_avg'] = df.groupby(['weekday','cat_id'])['lag_28'].transform('mean').astype(np.float16)\n",
    "df['cat_monthly_avg'] = df.groupby(['month','cat_id'])['lag_28'].transform('mean').astype(np.float16)\n",
    "df['cat_dept_avg'] = df.groupby(['cat_id','dept_id'])['lag_28'].transform('mean').astype(np.float16)\n",
    "df['cat_dept_daily_sold_avg'] = df.groupby(['weekday','dept_id','cat_id'])['lag_28'].transform('mean').astype(np.float16)\n",
    "df['cat_dept_monthly_avg'] = df.groupby(['month','dept_id','cat_id'])['lag_28'].transform('mean').astype(np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b90e5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['lag_28'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c46dec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expanding_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['lag_28'].transform(lambda x: x.expanding(2).mean()).astype(np.float16).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e8f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['lag_28'].transform('mean').astype(np.float16)\n",
    "df['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['lag_28'].transform('mean').astype(np.float16)\n",
    "df['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\n",
    "df.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac220365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sell_price'] = df['sell_price'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "#we left with 7 missing values after filling with interpolate, so fill with 0\n",
    "df['sell_price'] = df['sell_price'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4815479",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(1942,1970):\n",
    "  sales['d_' + str(day)] = 0\n",
    "  sales['d_' + str(day)] = sales['d_' + str(day)].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b6bb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data.pkl')\n",
    "del df\n",
    "gc.collect();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc0b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9412f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date','wday'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c030d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df[\"d\"] < 1914].drop(\"sold\", axis=1)\n",
    "X_val =  df[(df['d']>=1914) & (df['d']<=1941)].drop('sold',axis=1)\n",
    "X_test = df[df[\"d\"] >= 1942].drop(\"sold\", axis=1)\n",
    "\n",
    "y_train = df[df[\"d\"] < 1914][\"sold\"]\n",
    "y_val = df[(df['d']>=1914) & (df['d']<=1941)][\"sold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0320d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 34 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   id                       int32  \n",
      " 1   item_id                  int32  \n",
      " 2   dept_id                  int32  \n",
      " 3   cat_id                   int32  \n",
      " 4   store_id                 int32  \n",
      " 5   state_id                 int32  \n",
      " 6   d                        int16  \n",
      " 7   sold                     int16  \n",
      " 8   wm_yr_wk                 int64  \n",
      " 9   weekday                  int32  \n",
      " 10  month                    int8   \n",
      " 11  year                     int16  \n",
      " 12  event_name_1             int64  \n",
      " 13  event_type_1             int64  \n",
      " 14  event_name_2             int64  \n",
      " 15  event_type_2             int64  \n",
      " 16  snap_CA                  int8   \n",
      " 17  snap_TX                  int8   \n",
      " 18  snap_WI                  int8   \n",
      " 19  sell_price               int64  \n",
      " 20  lag_28                   float16\n",
      " 21  sold_lag_7               float16\n",
      " 22  sold_lag_14              float16\n",
      " 23  state_sold_avg           float16\n",
      " 24  dept_sold_avg            float16\n",
      " 25  cat_sold_avg             float16\n",
      " 26  cat_daily_avg            float16\n",
      " 27  cat_monthly_avg          float16\n",
      " 28  cat_dept_avg             float16\n",
      " 29  cat_dept_daily_sold_avg  float16\n",
      " 30  cat_dept_monthly_avg     float16\n",
      " 31  rolling_sold_mean        float16\n",
      " 32  expanding_sold_mean      float16\n",
      " 33  selling_trend            float16\n",
      "dtypes: float16(14), int16(3), int32(7), int64(6), int8(4)\n",
      "memory usage: 6.7 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635407ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808bd2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59181090, 34)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5f0c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>dept_sold_avg</th>\n",
       "      <th>cat_sold_avg</th>\n",
       "      <th>cat_daily_avg</th>\n",
       "      <th>cat_monthly_avg</th>\n",
       "      <th>cat_dept_avg</th>\n",
       "      <th>cat_dept_daily_sold_avg</th>\n",
       "      <th>cat_dept_monthly_avg</th>\n",
       "      <th>rolling_sold_mean</th>\n",
       "      <th>expanding_sold_mean</th>\n",
       "      <th>selling_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id  d  sold  wm_yr_wk  \\\n",
       "0  14370     1437        3       1         0         0  1     0         0   \n",
       "1  14380     1438        3       1         0         0  1     0         0   \n",
       "2  14390     1439        3       1         0         0  1     0         0   \n",
       "3  14400     1440        3       1         0         0  1     0         0   \n",
       "4  14410     1441        3       1         0         0  1     0         0   \n",
       "\n",
       "   weekday  ...  dept_sold_avg  cat_sold_avg  cat_daily_avg  cat_monthly_avg  \\\n",
       "0        2  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "1        2  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "2        2  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "3        2  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "4        2  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "\n",
       "   cat_dept_avg  cat_dept_daily_sold_avg  cat_dept_monthly_avg  \\\n",
       "0      0.703125                 0.871094              0.681152   \n",
       "1      0.703125                 0.871094              0.681152   \n",
       "2      0.703125                 0.871094              0.681152   \n",
       "3      0.703125                 0.871094              0.681152   \n",
       "4      0.703125                 0.871094              0.681152   \n",
       "\n",
       "   rolling_sold_mean  expanding_sold_mean  selling_trend  \n",
       "0                0.0                  0.0            NaN  \n",
       "1                0.0                  0.0            NaN  \n",
       "2                0.0                  0.0            NaN  \n",
       "3                0.0                  0.0            NaN  \n",
       "4                0.0                  0.0            NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79a4962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58327370, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b45bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>dept_sold_avg</th>\n",
       "      <th>cat_sold_avg</th>\n",
       "      <th>cat_daily_avg</th>\n",
       "      <th>cat_monthly_avg</th>\n",
       "      <th>cat_dept_avg</th>\n",
       "      <th>cat_dept_daily_sold_avg</th>\n",
       "      <th>cat_dept_monthly_avg</th>\n",
       "      <th>rolling_sold_mean</th>\n",
       "      <th>expanding_sold_mean</th>\n",
       "      <th>selling_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id  d  wm_yr_wk  weekday  \\\n",
       "0  14370     1437        3       1         0         0  1         0        2   \n",
       "1  14380     1438        3       1         0         0  1         0        2   \n",
       "2  14390     1439        3       1         0         0  1         0        2   \n",
       "3  14400     1440        3       1         0         0  1         0        2   \n",
       "4  14410     1441        3       1         0         0  1         0        2   \n",
       "\n",
       "   month  ...  dept_sold_avg  cat_sold_avg  cat_daily_avg  cat_monthly_avg  \\\n",
       "0      1  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "1      1  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "2      1  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "3      1  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "4      1  ...       0.703125      0.566895       0.695801         0.555664   \n",
       "\n",
       "   cat_dept_avg  cat_dept_daily_sold_avg  cat_dept_monthly_avg  \\\n",
       "0      0.703125                 0.871094              0.681152   \n",
       "1      0.703125                 0.871094              0.681152   \n",
       "2      0.703125                 0.871094              0.681152   \n",
       "3      0.703125                 0.871094              0.681152   \n",
       "4      0.703125                 0.871094              0.681152   \n",
       "\n",
       "   rolling_sold_mean  expanding_sold_mean  selling_trend  \n",
       "0                0.0                  0.0            NaN  \n",
       "1                0.0                  0.0            NaN  \n",
       "2                0.0                  0.0            NaN  \n",
       "3                0.0                  0.0            NaN  \n",
       "4                0.0                  0.0            NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace9d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"id\"] = prices[\"item_id\"].astype(str) + \"_\" + prices[\"store_id\"].astype(str) + \"_evaluation\"\n",
    "calendar[\"d\"] = calendar[\"d\"].apply(lambda a: int(a.split(\"_\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35130022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7cc98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:29<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/qcw171717/other-naive-forecasts-submission-score/notebook\n",
    "\n",
    "for day in tqdm(range(1886, 1914)):  \n",
    "    wk_id = list(calendar[calendar[\"d\"]==day][\"wm_yr_wk\"])[0]\n",
    "    wk_price = prices[prices[\"wm_yr_wk\"]==wk_id]\n",
    "    df_sales = sales.merge(wk_price[[\"sell_price\", \"id\"]], on=[\"id\"], how='inner')\n",
    "    df_sales[\"unit_sales_\" + str(day)] = df_sales[\"sell_price\"] * df_sales[\"d_\" + str(day)]\n",
    "    df_sales.drop(columns=[\"sell_price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [a for a in df_sales.columns if a.find(\"unit_sales\")==0]\n",
    "df_sales[\"sales\"] = df_sales[col]\n",
    "df_sales[\"weight\"] = df_sales[\"sales\"] / df_sales[\"sales\"].sum()\n",
    "df_sales.drop(columns=[\"sales\", col[0]], axis=1, inplace=True)\n",
    "df_sales[\"weight\"] /= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34d222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_level = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n",
    "              6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], 9: [\"store_id\", \"dept_id\"],\n",
    "              10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6156f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate rmsse \n",
    "\n",
    "h = 28\n",
    "n = 1913\n",
    "\n",
    "def RMSSE(ground_truth, forecast, train_series):\n",
    "    \n",
    "    num = ((ground_truth - forecast)**2).sum(axis=1)\n",
    "    den = 1/(n-1) * ((train_series[:, 1:] - train_series[:, :-1]) ** 2).sum(axis=1)\n",
    "    rmsse = (1/h * num/den) ** 0.5\n",
    "\n",
    "    return rmsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8191ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X_train, y_train, model):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    for d in range(1914, 1942):\n",
    "        df_sales['F_' + str(d)] = model.predict(X_val[X_val['d']==d])\n",
    "    \n",
    "    data = df_sales[[a for a in df_sales.columns if a.find(\"d_\") == 0 or a.find(\"F_\") == 0]]\n",
    "    data = data.sum()\n",
    "\n",
    "    aggregated_df = pd.DataFrame(data).transpose()    \n",
    "    aggregated_df[\"level\"] = 1\n",
    "    aggregated_df[\"weight\"] = 1/12    \n",
    "    columns = aggregated_df.columns  \n",
    "\n",
    "    for lev in aggregation_level:\n",
    "        df_t = df_sales.groupby(by=aggregation_level[lev]).sum().reset_index()\n",
    "        df_t[\"level\"] = lev\n",
    "        aggregated_df = aggregated_df.append(df_t[columns])     \n",
    "\n",
    "    train_columns = [a for a in df_sales.columns if a.find(\"d_\") == 0 and int(a.split('_')[1]) < 1914]\n",
    "    actual_value_columns = [a for a in df_sales.columns if a.find(\"d_\") == 0 and int(a.split('_')[1]) in range(1914, 1942)]\n",
    "    forecast_value_columns = [a for a in df_sales.columns if a.find(\"F_\") == 0]    \n",
    "\n",
    "    ground_truth_df = np.array(df_sales[actual_value_columns])\n",
    "    forecast_df = np.array(df_sales[forecast_value_columns])\n",
    "    train_series_df = np.array(df_sales[train_columns])\n",
    "\n",
    "    ground_truth_agg_df = np.array(aggregated_df[actual_value_columns])\n",
    "    forecast_agg_df = np.array(aggregated_df[forecast_value_columns])\n",
    "    train_series_agg_df = np.array(aggregated_df[train_columns])\n",
    "\n",
    "    df_sales[\"rmsse\"] = RMSSE(ground_truth_df, forecast_df, train_series_df)\n",
    "    aggregated_df[\"rmsse\"] = RMSSE(ground_truth_agg_df, forecast_agg_df, train_series_agg_df)\n",
    "\n",
    "    df_sales[\"wrmsse\"] = df_sales[\"weight\"] * df_sales[\"rmsse\"]\n",
    "    aggregated_df[\"wrmsse\"] = aggregated_df[\"weight\"] * aggregated_df[\"rmsse\"]\n",
    "\n",
    "    print(df_sales[\"wrmsse\"].sum() + aggregated_df[\"wrmsse\"].sum())\n",
    "    \n",
    "    return (df_sales[\"wrmsse\"].sum() + aggregated_df[\"wrmsse\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b696d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████                                                    | 1/3 [1:07:41<2:15:23, 4061.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.452178916309831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████                          | 2/3 [2:17:39<1:09:01, 4141.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.452178916309831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [3:30:50<00:00, 4216.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.452178916309831\n",
      "Wall time: 3h 30min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wrmsse=[]\n",
    "alpha_lst = [10,15,20]\n",
    "lr_rate=.01\n",
    "for alpha in tqdm(alpha_lst):\n",
    "\n",
    "\n",
    "    xgb_model=XGBRegressor(n_estimators=10,learning_rate=lr_rate,n_jobs=-1)\n",
    "    \n",
    "    WRMSSE = hyperparameter_tuning(X_train, y_train, xgb_model)\n",
    "\n",
    "    wrmsse.append(WRMSSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76bb6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minpos = wrmsse.index(min(wrmsse))\n",
    "alpha=alpha_lst[minpos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f36f3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"lr_rate\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             lr_rate=0.01, max_delta_step=0, max_depth=6, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=10, n_jobs=-1,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='approx', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model on best parameters\n",
    "\n",
    "m_xgb= XGBRegressor(n_estimators=alpha,lr_rate=.01 ,n_jobs=-1)\n",
    "\n",
    "m_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4947758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('m_xgb_1', 'wb') as file:\n",
    "        pickle.dump(m_xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17faa1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b086011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(1914, 1942):\n",
    "    df_sales['F_' + str(d)] = m_xgb.predict(X_val[X_val['d']==d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb5fb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WRMSSE(df_sales):\n",
    "\n",
    "  aggregation_level = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n",
    "              6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], 9: [\"store_id\", \"dept_id\"],\n",
    "              10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}\n",
    "\n",
    "  data = df_sales[[a for a in df_sales.columns if a.find(\"d_\") == 0 or a.find(\"F_\") == 0]]\n",
    "  data = data.sum()\n",
    "\n",
    "  aggregated_df = pd.DataFrame(data).transpose()    \n",
    "  aggregated_df[\"level\"] = 1\n",
    "  aggregated_df[\"weight\"] = 1/12    \n",
    "  columns = aggregated_df.columns  \n",
    "\n",
    "  for lev in aggregation_level:\n",
    "      df_t = df_sales.groupby(by=aggregation_level[lev]).sum().reset_index()\n",
    "      df_t[\"level\"] = lev\n",
    "      aggregated_df = aggregated_df.append(df_t[columns])     \n",
    "\n",
    "  #print(df_sales.shape[0], aggregated_df.shape[0], df_sales.shape[0] + aggregated_df.shape[0])\n",
    "  #print(aggregated_df[\"weight\"].sum() + df_sales[\"weight\"].sum())    \n",
    "\n",
    "  train_columns = [a for a in df_sales.columns if a.find(\"d_\") == 0 and int(a.split('_')[1]) < 1914]\n",
    "  actual_value_columns = [a for a in df_sales.columns if a.find(\"d_\") == 0 and int(a.split('_')[1]) in range(1914, 1942)]\n",
    "  forecast_value_columns = [a for a in df_sales.columns if a.find(\"F_\") == 0]    \n",
    "\n",
    "\n",
    "  ground_truth_df = np.array(df_sales[actual_value_columns])\n",
    "  forecast_df = np.array(df_sales[forecast_value_columns])\n",
    "  train_series_df = np.array(df_sales[train_columns])\n",
    "\n",
    "  ground_truth_agg_df = np.array(aggregated_df[actual_value_columns])\n",
    "  forecast_agg_df = np.array(aggregated_df[forecast_value_columns])\n",
    "  train_series_agg_df = np.array(aggregated_df[train_columns])\n",
    "\n",
    "  df_sales[\"rmsse\"] = RMSSE(ground_truth_df, forecast_df, train_series_df)\n",
    "  aggregated_df[\"rmsse\"] = RMSSE(ground_truth_agg_df, forecast_agg_df, train_series_agg_df)\n",
    "\n",
    "  df_sales[\"wrmsse\"] = df_sales[\"weight\"] * df_sales[\"rmsse\"]\n",
    "  aggregated_df[\"wrmsse\"] = aggregated_df[\"weight\"] * aggregated_df[\"rmsse\"]\n",
    "\n",
    "  print(\"df\", df_sales[\"wrmsse\"].sum())\n",
    "  print(\"agg_df\",aggregated_df[\"wrmsse\"].sum())\n",
    "\n",
    "  WRMSSE = df_sales[\"wrmsse\"].sum() + aggregated_df[\"wrmsse\"].sum()\n",
    "  #print(WRMSSE)\n",
    "\n",
    "  return WRMSSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0627929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df 0.08944588827619057\n",
      "agg_df 0.8243029284315251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9137488167077157"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRMSSE(df_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model=xgb.XGBRegressor(n_estimators=10,learning_rate=.01,)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=10, max_depth=15,n_jobs=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9933d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
